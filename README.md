# RELACT
This is the code repository for reproducing the results of the paper titled ‚ÄúRELACT: Instance Segmentation Method for Remote Sensing Small Object Based on Phase Enhancement and Optimized Sorting.‚Äù
![Fig 1](https://github.com/user-attachments/assets/7c55ffcc-2d20-49d7-8d58-459aa95e8ea3)
# Required environment
We select YOLACT with a ResNet50 backbone as the baseline model for improvement. During the image preprocessing stage, input images are resized using bilinear interpolation, with the long edge adjusted to 1000 pixels and the short edge to 600 pixels. All experiments are implemented using the PyTorch framework, running on Ubuntu 20.04 with CUDA v11.7 and PyTorch 2.0.1. Both training and testing are conducted on two NVIDIA RTX 4090 GPUs. The random seed is set to 42 to ensure reproducibility, and mixed-precision training is employed to improve computational efficiency. To reduce memory consumption, training is divided into two stages: a frozen stage and an unfrozen stage. The model is optimized using SGD with a momentum of 0.9. The learning rate follows a cosine decay schedule, and the weight decay is set to 0.0001. During evaluation, the Non-Maximum Suppression (NMS) threshold is set to 0.6, and the confidence score threshold is set to 0.5. All baseline models used in the comparative experiments are implemented based on the MMDetection toolbox.
# Installation
We encourage you to create a virtual environment with Anaconda. Once you have cloned the repository, cd to the root directory and üëá
## 1. Install dependencies.
Use pip to install the package in requirements. txt: pip install - r requirements. txt
## 2. Installation environment
conda install pytorch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 pytorch-cuda=11.7 -c pytorch -c nvidia
## Datasets and Evaluation Metrics
We conduct extensive evaluations of the proposed method on the iSAID-100, NWPU VHR-10, and HRSID datasets. All three datasets provide both bounding box annotations and pixel-level annotations. Accordingly, we report performance on both object detection and image segmentation tasks. 
iSAID-100 is a subset of the iSAID dataset, comprising 40% of its content, and serves as a representative aerial imagery dataset primarily designed for instance segmentation tasks. iSAID-100 contains 1,122 high-resolution aerial images and 262,180 annotated instances across 15 distinct object categories. 
NWPU VHR-10 is a high-resolution remote sensing image dataset specifically designed for object detection tasks in high-resolution remote sensing imagery. Recently, instance-level mask annotations have been added to the dataset. NWPU VHR-10 comprises images captured from a variety of scenes and includes 10 common object categories. The dataset consists of 800 high-resolution images, among which 650 are positive samples and 150 are negative samples.
HRSID is a large-scale remote sensing image dataset specifically designed for ship detection and instance segmentation tasks in synthetic aperture radar (SAR) imagery. It contains 5,604 high-resolution SAR images, covering a total of 16,951 ship instances, with "ship" being the only object category.
The COCO-style evaluation metrics include AP, AP50, AP75, APS, APM, and APL for both detection and segmentation tasks. In addition to accuracy metrics, we also evaluate model efficiency using the Params, FLOPs, and FPS. APS refers to the average precision for detection and segmentation of small-object instances in images with an area smaller than 32√ó32 pixel. APM refers to the average precision for detection and segmentation of medium-object instances in images with an area between 32√ó32 and 96√ó96 pixels. APL refers to the average precision for detection and segmentation of large-object instances in images with an area greater than or equal to 96√ó96 pixels.
# Public statement
We fully recognize the importance of open-source code in promoting research reproducibility and advancing scientific progress. However, due to the paper currently being under review, tight revision deadlines, and the fact that the algorithms used in this project are part of an ongoing patent application, the code release must undergo an internal approval process. As a result, we are unable to make it publicly available at this time. We plan to complete the necessary organizational and review procedures as soon as the work is officially published, and will release the source code and key model parameters from the project repository to facilitate reproducibility and further research.
